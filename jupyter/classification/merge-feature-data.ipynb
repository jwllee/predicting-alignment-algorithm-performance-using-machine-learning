{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/jonathan/.ipython/profile_default/startup/01-setup.py\n",
    "# start up settings for jupyter notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# use plt.style.available() to check out available styles\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 15.0\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set the max column width\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "# to avoid have warnings from chained assignments\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fp = '../../prediction-data/clst-IS2017-2-repacked-predictive-data.csv'\n",
    "df = pd.read_csv(fp, header=[0, 1])\n",
    "df.rename(columns={\n",
    "    'Unnamed: 0_level_1': '',\n",
    "    'Unnamed: 1_level_1': '',\n",
    "    'Unnamed: 2_level_1': ''\n",
    "}, level=1, inplace=True)\n",
    "\n",
    "columns = list(df.columns)\n",
    "decomposition_type = 'sese_manual'\n",
    "df['decomposition'] = decomposition_type\n",
    "columns = [('model', ''), ('log', ''), ('decomposition', ''), ('SP label', '')] + columns[3:]\n",
    "df = df[columns]\n",
    "\n",
    "df.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../prediction-data/'\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    if 'inc0' in f or 'final-data' in f:\n",
    "        continue\n",
    "    fp = os.path.join(data_dir, f)\n",
    "    \n",
    "    if not os.path.isfile(fp):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(fp, header=[0, 1])\n",
    "    df.rename(columns={\n",
    "        'Unnamed: 0_level_1': '',\n",
    "        'Unnamed: 1_level_1': '',\n",
    "        'Unnamed: 2_level_1': '',\n",
    "        'Unnamed: 3_level_1': ''\n",
    "    }, level=1, inplace=True)\n",
    "    df_list.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering all invalid no. of rows: 330130\n",
      "After filtering all invalid no. of rows: 329876\n",
      "254 traces invalid for all algorithms\n",
      "Before filtering negative cost rows: 329876\n",
      "After filtering negative cost rows: 329289\n",
      "587 traces invalid\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.concat(df_list, axis=0, sort=False)\n",
    "base_df.set_index(['model', 'log', 'decomposition', 'SP label'], inplace=True)\n",
    "\n",
    "# remove traces for which all algorithms are invalid\n",
    "astar_invalid = (base_df.loc[:,('is_valid', 'astar')] == False) | (base_df.loc[:, ('is_valid', 'astar')].isnull())\n",
    "inc3_invalid = (base_df.loc[:,('is_valid', 'inc3')] == False) | (base_df.loc[:,('is_valid', 'inc3')].isnull())\n",
    "recomp_astar_invalid = (base_df.loc[:,('is_valid', 'recomp-astar')] == False) | (base_df.loc[:,('is_valid', 'recomp-astar')].isnull())\n",
    "recomp_inc3_invalid = (base_df.loc[:,('is_valid', 'recomp-inc3')] == False) | (base_df.loc[:,('is_valid', 'recomp-inc3')].isnull())\n",
    "all_invalid = astar_invalid & inc3_invalid & recomp_astar_invalid & recomp_inc3_invalid\n",
    "\n",
    "before_n_rows = base_df.shape[0]\n",
    "print('Before filtering all invalid no. of rows: {}'.format(before_n_rows))\n",
    "\n",
    "base_df = base_df.loc[~all_invalid, :]\n",
    "\n",
    "after_n_rows = base_df.shape[0]\n",
    "print('After filtering all invalid no. of rows: {}'.format(after_n_rows))\n",
    "print('{} traces invalid for all algorithms'.format(before_n_rows - after_n_rows))\n",
    "\n",
    "cost_is_neg_recomp_astar = base_df.loc[:, ('Cost of the alignment', 'recomp-astar')] == -1\n",
    "cost_is_neg_recomp_inc3 = base_df.loc[:, ('Cost of the alignment', 'recomp-inc3')] == -1\n",
    "\n",
    "before_n_rows = base_df.shape[0]\n",
    "print('Before filtering negative cost rows: {}'.format(before_n_rows))\n",
    "\n",
    "base_df = base_df.loc[~(cost_is_neg_recomp_astar | cost_is_neg_recomp_inc3), :]\n",
    "\n",
    "after_n_rows = base_df.shape[0]\n",
    "print('After filtering negative cost rows: {}'.format(after_n_rows))\n",
    "print('{} traces invalid'.format(before_n_rows - after_n_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cost of the alignment', 'Heuristics computed', 'Heuristics derived',\n",
       "       'Heuristics estimated', 'Markings added to closed set',\n",
       "       'Markings polled from queue', 'Markings queued', 'Markings reached',\n",
       "       'Min', 'Number of splits when splitting marking',\n",
       "       'Number of times replay was restarted', 'Size of the constraintset',\n",
       "       'Time to compute alignment (us)', 'Total Time including setup (us)',\n",
       "       'is_valid', 'n_invis_move', 'n_log_move', 'n_model_move', 'n_sync_move',\n",
       "       'result_dir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.columns.get_level_values(level=0).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and correct errors with algorithms yielding invalid alignments but has the minimum time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Time including setup (us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false min astar: 0\n",
      "No. of false min inc3: 0\n",
      "No. of false min recomp astar: 0\n",
      "No. of false min recomp inc3: 0\n"
     ]
    }
   ],
   "source": [
    "min_total_astar = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'astar'\n",
    "min_total_inc3 = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'inc3'\n",
    "min_total_r_astar = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-astar'\n",
    "min_total_r_inc3 = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-inc3'\n",
    "\n",
    "false_min_astar = base_df.loc[astar_invalid & min_total_astar, ]\n",
    "false_min_inc3 = base_df.loc[inc3_invalid & min_total_inc3, ]\n",
    "false_min_r_astar = base_df.loc[recomp_astar_invalid & min_total_r_astar, ]\n",
    "false_min_r_inc3 = base_df.loc[recomp_inc3_invalid & min_total_r_inc3, ]\n",
    "\n",
    "print('No. of false min astar: {}'.format(false_min_astar.shape[0]))\n",
    "print('No. of false min inc3: {}'.format(false_min_inc3.shape[0]))\n",
    "print('No. of false min recomp astar: {}'.format(false_min_r_astar.shape[0]))\n",
    "print('No. of false min recomp inc3: {}'.format(false_min_r_inc3.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to compute alignment (us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false min align time astar: 0\n",
      "No. of false min align time inc3: 0\n",
      "No. of false min align time recomp astar: 0\n",
      "No. of false min align time recomp inc3: 0\n"
     ]
    }
   ],
   "source": [
    "col = ('Min', 'Time to compute alignment (us)')\n",
    "min_align_astar = base_df.loc[:,col] == 'astar'\n",
    "min_align_inc3 = base_df.loc[:,col] == 'inc3'\n",
    "min_align_r_astar = base_df.loc[:,col] == 'recomp-astar'\n",
    "min_align_r_inc3 = base_df.loc[:,col] == 'recomp-inc3'\n",
    "\n",
    "false_min_astar = base_df.loc[astar_invalid & min_align_astar, ]\n",
    "false_min_inc3 = base_df.loc[inc3_invalid & min_align_inc3, ]\n",
    "false_min_r_astar = base_df.loc[recomp_astar_invalid & min_align_r_astar, ]\n",
    "false_min_r_inc3 = base_df.loc[recomp_inc3_invalid & min_align_r_inc3, ]\n",
    "\n",
    "print('No. of false min align time astar: {}'.format(false_min_astar.shape[0]))\n",
    "print('No. of false min align time inc3: {}'.format(false_min_inc3.shape[0]))\n",
    "print('No. of false min align time recomp astar: {}'.format(false_min_r_astar.shape[0]))\n",
    "print('No. of false min align time recomp inc3: {}'.format(false_min_r_inc3.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Cost of the alignment</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Heuristics computed</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Heuristics derived</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">n_log_move</th>\n",
       "      <th colspan=\"4\" halign=\"left\">n_model_move</th>\n",
       "      <th colspan=\"4\" halign=\"left\">n_sync_move</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>...</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "      <td>329289.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.658610</td>\n",
       "      <td>57.540483</td>\n",
       "      <td>57.722827</td>\n",
       "      <td>57.724036</td>\n",
       "      <td>693.739241</td>\n",
       "      <td>6.518614</td>\n",
       "      <td>757.428879</td>\n",
       "      <td>82.172432</td>\n",
       "      <td>303.494125</td>\n",
       "      <td>266.142868</td>\n",
       "      <td>...</td>\n",
       "      <td>4.261983</td>\n",
       "      <td>4.270969</td>\n",
       "      <td>3.763053</td>\n",
       "      <td>3.741823</td>\n",
       "      <td>3.775750</td>\n",
       "      <td>3.753587</td>\n",
       "      <td>66.944872</td>\n",
       "      <td>66.982675</td>\n",
       "      <td>67.012105</td>\n",
       "      <td>67.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>136.368084</td>\n",
       "      <td>136.173015</td>\n",
       "      <td>136.703001</td>\n",
       "      <td>136.709396</td>\n",
       "      <td>2009.759991</td>\n",
       "      <td>31.558585</td>\n",
       "      <td>2051.419583</td>\n",
       "      <td>43.779062</td>\n",
       "      <td>633.343098</td>\n",
       "      <td>691.859813</td>\n",
       "      <td>...</td>\n",
       "      <td>10.336150</td>\n",
       "      <td>10.379335</td>\n",
       "      <td>8.496652</td>\n",
       "      <td>8.410476</td>\n",
       "      <td>8.535595</td>\n",
       "      <td>8.440035</td>\n",
       "      <td>35.497537</td>\n",
       "      <td>35.645809</td>\n",
       "      <td>35.635604</td>\n",
       "      <td>35.635837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>38800.000000</td>\n",
       "      <td>648.000000</td>\n",
       "      <td>25251.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>23185.000000</td>\n",
       "      <td>16646.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cost of the alignment                                               \\\n",
       "                      astar           inc3   recomp-astar    recomp-inc3   \n",
       "count         329289.000000  329289.000000  329289.000000  329289.000000   \n",
       "mean              57.658610      57.540483      57.722827      57.724036   \n",
       "std              136.368084     136.173015     136.703001     136.709396   \n",
       "min                0.000000       0.000000       0.000000       0.000000   \n",
       "25%                0.000000       0.000000       0.000000       0.000000   \n",
       "50%                0.000000       0.000000       0.000000       0.000000   \n",
       "75%               36.000000      36.000000      36.000000      36.000000   \n",
       "max             1256.000000    1256.000000    1256.000000    1256.000000   \n",
       "\n",
       "      Heuristics computed                                               \\\n",
       "                    astar           inc3   recomp-astar    recomp-inc3   \n",
       "count       329289.000000  329289.000000  329289.000000  329289.000000   \n",
       "mean           693.739241       6.518614     757.428879      82.172432   \n",
       "std           2009.759991      31.558585    2051.419583      43.779062   \n",
       "min              1.000000       1.000000      12.000000      12.000000   \n",
       "25%              1.000000       1.000000      71.000000      71.000000   \n",
       "50%              1.000000       1.000000      74.000000      75.000000   \n",
       "75%             64.000000       2.000000     149.000000      79.000000   \n",
       "max          38800.000000     648.000000   25251.000000     989.000000   \n",
       "\n",
       "      Heuristics derived                     ...           n_log_move  \\\n",
       "                   astar           inc3      ...         recomp-astar   \n",
       "count      329289.000000  329289.000000      ...        329289.000000   \n",
       "mean          303.494125     266.142868      ...             4.261983   \n",
       "std           633.343098     691.859813      ...            10.336150   \n",
       "min             3.000000       3.000000      ...             0.000000   \n",
       "25%            58.000000      58.000000      ...             0.000000   \n",
       "50%            83.000000      83.000000      ...             0.000000   \n",
       "75%           181.000000     170.000000      ...             2.000000   \n",
       "max         23185.000000   16646.000000      ...           100.000000   \n",
       "\n",
       "                       n_model_move                                \\\n",
       "         recomp-inc3          astar           inc3   recomp-astar   \n",
       "count  329289.000000  329289.000000  329289.000000  329289.000000   \n",
       "mean        4.270969       3.763053       3.741823       3.775750   \n",
       "std        10.379335       8.496652       8.410476       8.535595   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         2.000000       2.000000       2.000000       2.000000   \n",
       "max       100.000000      78.000000      78.000000      78.000000   \n",
       "\n",
       "                        n_sync_move                                \\\n",
       "         recomp-inc3          astar           inc3   recomp-astar   \n",
       "count  329289.000000  329289.000000  329289.000000  329289.000000   \n",
       "mean        3.753587      66.944872      66.982675      67.012105   \n",
       "std         8.440035      35.497537      35.645809      35.635604   \n",
       "min         0.000000      -1.000000      -1.000000       1.000000   \n",
       "25%         0.000000      45.000000      45.000000      45.000000   \n",
       "50%         0.000000      57.000000      57.000000      57.000000   \n",
       "75%         2.000000      79.000000      79.000000      79.000000   \n",
       "max        78.000000     419.000000     419.000000     419.000000   \n",
       "\n",
       "                      \n",
       "         recomp-inc3  \n",
       "count  329289.000000  \n",
       "mean       67.003119  \n",
       "std        35.635837  \n",
       "min         0.000000  \n",
       "25%        45.000000  \n",
       "50%        57.000000  \n",
       "75%        79.000000  \n",
       "max       419.000000  \n",
       "\n",
       "[8 rows x 68 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and trace features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '../../prediction-data/features/net1-feature.csv'\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "fp = '../../prediction-data/features/P241-feature.csv'\n",
    "df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>trace_length</th>\n",
       "      <th>n_activity</th>\n",
       "      <th>activity_repeat_mean</th>\n",
       "      <th>activity_repeat_std</th>\n",
       "      <th>snp_n_transition</th>\n",
       "      <th>snp_n_inv_transition</th>\n",
       "      <th>snp_n_dup_transition</th>\n",
       "      <th>snp_n_uniq_transition</th>\n",
       "      <th>snp_inv_transition_in_degree_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>subnet_n_dup_transition_mean</th>\n",
       "      <th>subnet_n_dup_transition_std</th>\n",
       "      <th>subnet_n_uniq_transition_mean</th>\n",
       "      <th>subnet_n_uniq_transition_std</th>\n",
       "      <th>subnet_n_place_mean</th>\n",
       "      <th>subnet_n_place_std</th>\n",
       "      <th>subnet_n_arc_mean</th>\n",
       "      <th>subnet_n_arc_std</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.139785</td>\n",
       "      <td>0.543567</td>\n",
       "      <td>355.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.032967</td>\n",
       "      <td>0.179540</td>\n",
       "      <td>331.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_10</td>\n",
       "      <td>112.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.244444</td>\n",
       "      <td>0.768935</td>\n",
       "      <td>367.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_100</td>\n",
       "      <td>105.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.613244</td>\n",
       "      <td>353.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_101</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.011494</td>\n",
       "      <td>0.107211</td>\n",
       "      <td>319.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     caseid  trace_length  n_activity  activity_repeat_mean  \\\n",
       "0    case_0         106.0        93.0              1.139785   \n",
       "1    case_1          94.0        91.0              1.032967   \n",
       "2   case_10         112.0        90.0              1.244444   \n",
       "3  case_100         105.0        91.0              1.153846   \n",
       "4  case_101          88.0        87.0              1.011494   \n",
       "\n",
       "   activity_repeat_std  snp_n_transition  snp_n_inv_transition  \\\n",
       "0             0.543567             355.0                  26.0   \n",
       "1             0.179540             331.0                  26.0   \n",
       "2             0.768935             367.0                  26.0   \n",
       "3             0.613244             353.0                  26.0   \n",
       "4             0.107211             319.0                  26.0   \n",
       "\n",
       "   snp_n_dup_transition  snp_n_uniq_transition  \\\n",
       "0                  40.0                  289.0   \n",
       "1                  12.0                  293.0   \n",
       "2                  62.0                  279.0   \n",
       "3                  42.0                  285.0   \n",
       "4                   4.0                  289.0   \n",
       "\n",
       "   snp_inv_transition_in_degree_mean ...   subnet_n_dup_transition_mean  \\\n",
       "0                                2.0 ...                            0.0   \n",
       "1                                2.0 ...                            0.0   \n",
       "2                                2.0 ...                            0.0   \n",
       "3                                2.0 ...                            0.0   \n",
       "4                                2.0 ...                            0.0   \n",
       "\n",
       "   subnet_n_dup_transition_std  subnet_n_uniq_transition_mean  \\\n",
       "0                          0.0                           40.0   \n",
       "1                          0.0                           40.0   \n",
       "2                          0.0                           40.0   \n",
       "3                          0.0                           40.0   \n",
       "4                          0.0                           40.0   \n",
       "\n",
       "   subnet_n_uniq_transition_std  subnet_n_place_mean  subnet_n_place_std  \\\n",
       "0                     41.581246                 52.0           67.557383   \n",
       "1                     41.581246                 52.0           67.557383   \n",
       "2                     41.581246                 52.0           67.557383   \n",
       "3                     41.581246                 52.0           67.557383   \n",
       "4                     41.581246                 52.0           67.557383   \n",
       "\n",
       "   subnet_n_arc_mean  subnet_n_arc_std  decomposition  log  \n",
       "0         116.666667        141.454351    sese_manual  L50  \n",
       "1         116.666667        141.454351    sese_manual  L50  \n",
       "2         116.666667        141.454351    sese_manual  L50  \n",
       "3         116.666667        141.454351    sese_manual  L50  \n",
       "4         116.666667        141.454351    sese_manual  L50  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = '../../prediction-data/features/'\n",
    "extra_featur_dir = '../../prediction-data/features/extra-extra-feature/'\n",
    "\n",
    "feature_df_dict = dict()\n",
    "extra_feature_df_dict = dict()\n",
    "\n",
    "for f in os.listdir(feature_dir):\n",
    "    fp = os.path.join(feature_dir, f)\n",
    "    \n",
    "    if not os.path.isfile(fp):\n",
    "        continue\n",
    "    \n",
    "    model = f.replace('-feature.csv', '')\n",
    "    df = pd.read_csv(fp)\n",
    "    df['model'] = model\n",
    "    feature_df_dict[model] = df\n",
    "\n",
    "for f in os.listdir(extra_featur_dir):\n",
    "    fp = os.path.join(extra_featur_dir, f)\n",
    "    \n",
    "    if not os.path.isfile(fp):\n",
    "        continue\n",
    "        \n",
    "    model = f.replace('-extra-extra-feature.csv', '')\n",
    "    df = pd.read_csv(fp)\n",
    "    df['model'] = model\n",
    "    extra_feature_df_dict[model] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(feature_df_dict.keys()).difference(set(extra_feature_df_dict.keys()))) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the feature dfs with the extra feature dfs\n",
    "feature_df_list = []\n",
    "for key in feature_df_dict.keys():\n",
    "    df0 = feature_df_dict[key]\n",
    "    df1 = extra_feature_df_dict[key]\n",
    "    df = df0.merge(df1, on=['model', 'log', 'caseid'])\n",
    "    feature_df_list.append(df)\n",
    "feature_df = pd.concat(feature_df_list, axis=0, sort=False)\n",
    "\n",
    "out_fp = '../../prediction-data/features/merged-feature.csv'\n",
    "# feature_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.rename(columns={'caseid': 'SP label'}, inplace=True) # for later convenience on merging with base_df\n",
    "feature_df.set_index(['model', 'log', 'decomposition', 'SP label'], inplace=True)\n",
    "feature_df.columns = pd.MultiIndex.from_product([['model_trace_features'], feature_df.columns])\n",
    "feature_df.loc[:,('model_trace_features', 'activity_repeat_std')].fillna(0., inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = base_df.merge(feature_df, on=('model', 'log', 'decomposition', 'SP label'), how='inner')\n",
    "out_fp = '../../prediction-data/final-data.csv'\n",
    "\n",
    "# export dataframe after computing k times differences!\n",
    "# full_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find instances where there are k times differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Total Time including setup (us)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>log</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>SP label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P430</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">L19</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">sese_manual</th>\n",
       "      <th>case_785</th>\n",
       "      <td>22874</td>\n",
       "      <td>37474</td>\n",
       "      <td>35761</td>\n",
       "      <td>45285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_69</th>\n",
       "      <td>17436</td>\n",
       "      <td>41131</td>\n",
       "      <td>36837</td>\n",
       "      <td>49677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_33</th>\n",
       "      <td>12774</td>\n",
       "      <td>28984</td>\n",
       "      <td>35404</td>\n",
       "      <td>47586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_797</th>\n",
       "      <td>26403</td>\n",
       "      <td>52129</td>\n",
       "      <td>40037</td>\n",
       "      <td>52829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_784</th>\n",
       "      <td>13038</td>\n",
       "      <td>28965</td>\n",
       "      <td>37256</td>\n",
       "      <td>47108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Total Time including setup (us)         \\\n",
       "                                                           astar   inc3   \n",
       "model log decomposition SP label                                          \n",
       "P430  L19 sese_manual   case_785                           22874  37474   \n",
       "                        case_69                            17436  41131   \n",
       "                        case_33                            12774  28984   \n",
       "                        case_797                           26403  52129   \n",
       "                        case_784                           13038  28965   \n",
       "\n",
       "                                                           \n",
       "                                 recomp-astar recomp-inc3  \n",
       "model log decomposition SP label                           \n",
       "P430  L19 sese_manual   case_785        35761       45285  \n",
       "                        case_69         36837       49677  \n",
       "                        case_33         35404       47586  \n",
       "                        case_797        40037       52829  \n",
       "                        case_784        37256       47108  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.loc[:, idx[('Total Time including setup (us)'), :]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itls\n",
    "\n",
    "algos = [\n",
    "    'astar', 'inc3', 'recomp-astar', 'recomp-inc3'\n",
    "]\n",
    "\n",
    "c_2 = itls.combinations(algos, 2)\n",
    "colnames = []\n",
    "\n",
    "for a0, a1 in c_2:\n",
    "    # compute the time[a0] / time[a1]\n",
    "    col_name = '{}_over_{}'.format(a0, a1)\n",
    "    colnames.append(col_name)\n",
    "    full_df[('Total Time including setup (us)', col_name)] = full_df[('Total Time including setup (us)', a0)] / full_df[('Total Time including setup (us)', a1)]\n",
    "\n",
    "k = 5\n",
    "full_df[('Total Time including setup (us)', 'max_diff')] = full_df.loc[:, idx[('Total Time including setup (us)'), tuple(colnames)]].max(axis=1)\n",
    "# base_df[('Total Time including setup (us)', 'at_least_{}'.format(k))] = base_df[('Total Time including setup (us)', 'max_diff')] >= k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"11\" halign=\"left\">Total Time including setup (us)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar_over_inc3</th>\n",
       "      <th>astar_over_recomp-astar</th>\n",
       "      <th>astar_over_recomp-inc3</th>\n",
       "      <th>inc3_over_recomp-astar</th>\n",
       "      <th>inc3_over_recomp-inc3</th>\n",
       "      <th>recomp-astar_over_recomp-inc3</th>\n",
       "      <th>max_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>log</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>SP label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P430</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">L19</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">sese_manual</th>\n",
       "      <th>case_785</th>\n",
       "      <td>22874</td>\n",
       "      <td>37474</td>\n",
       "      <td>35761</td>\n",
       "      <td>45285</td>\n",
       "      <td>0.610397</td>\n",
       "      <td>0.639635</td>\n",
       "      <td>0.505112</td>\n",
       "      <td>1.047901</td>\n",
       "      <td>0.827515</td>\n",
       "      <td>0.789688</td>\n",
       "      <td>1.047901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_69</th>\n",
       "      <td>17436</td>\n",
       "      <td>41131</td>\n",
       "      <td>36837</td>\n",
       "      <td>49677</td>\n",
       "      <td>0.423914</td>\n",
       "      <td>0.473328</td>\n",
       "      <td>0.350987</td>\n",
       "      <td>1.116568</td>\n",
       "      <td>0.827969</td>\n",
       "      <td>0.741530</td>\n",
       "      <td>1.116568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_33</th>\n",
       "      <td>12774</td>\n",
       "      <td>28984</td>\n",
       "      <td>35404</td>\n",
       "      <td>47586</td>\n",
       "      <td>0.440726</td>\n",
       "      <td>0.360807</td>\n",
       "      <td>0.268440</td>\n",
       "      <td>0.818665</td>\n",
       "      <td>0.609087</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>0.818665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_797</th>\n",
       "      <td>26403</td>\n",
       "      <td>52129</td>\n",
       "      <td>40037</td>\n",
       "      <td>52829</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.659465</td>\n",
       "      <td>0.499782</td>\n",
       "      <td>1.302021</td>\n",
       "      <td>0.986750</td>\n",
       "      <td>0.757860</td>\n",
       "      <td>1.302021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case_784</th>\n",
       "      <td>13038</td>\n",
       "      <td>28965</td>\n",
       "      <td>37256</td>\n",
       "      <td>47108</td>\n",
       "      <td>0.450129</td>\n",
       "      <td>0.349957</td>\n",
       "      <td>0.276768</td>\n",
       "      <td>0.777459</td>\n",
       "      <td>0.614864</td>\n",
       "      <td>0.790864</td>\n",
       "      <td>0.790864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Total Time including setup (us)         \\\n",
       "                                                           astar   inc3   \n",
       "model log decomposition SP label                                          \n",
       "P430  L19 sese_manual   case_785                           22874  37474   \n",
       "                        case_69                            17436  41131   \n",
       "                        case_33                            12774  28984   \n",
       "                        case_797                           26403  52129   \n",
       "                        case_784                           13038  28965   \n",
       "\n",
       "                                                                           \\\n",
       "                                 recomp-astar recomp-inc3 astar_over_inc3   \n",
       "model log decomposition SP label                                            \n",
       "P430  L19 sese_manual   case_785        35761       45285        0.610397   \n",
       "                        case_69         36837       49677        0.423914   \n",
       "                        case_33         35404       47586        0.440726   \n",
       "                        case_797        40037       52829        0.506494   \n",
       "                        case_784        37256       47108        0.450129   \n",
       "\n",
       "                                                          \\\n",
       "                                 astar_over_recomp-astar   \n",
       "model log decomposition SP label                           \n",
       "P430  L19 sese_manual   case_785                0.639635   \n",
       "                        case_69                 0.473328   \n",
       "                        case_33                 0.360807   \n",
       "                        case_797                0.659465   \n",
       "                        case_784                0.349957   \n",
       "\n",
       "                                                         \\\n",
       "                                 astar_over_recomp-inc3   \n",
       "model log decomposition SP label                          \n",
       "P430  L19 sese_manual   case_785               0.505112   \n",
       "                        case_69                0.350987   \n",
       "                        case_33                0.268440   \n",
       "                        case_797               0.499782   \n",
       "                        case_784               0.276768   \n",
       "\n",
       "                                                                               \\\n",
       "                                 inc3_over_recomp-astar inc3_over_recomp-inc3   \n",
       "model log decomposition SP label                                                \n",
       "P430  L19 sese_manual   case_785               1.047901              0.827515   \n",
       "                        case_69                1.116568              0.827969   \n",
       "                        case_33                0.818665              0.609087   \n",
       "                        case_797               1.302021              0.986750   \n",
       "                        case_784               0.777459              0.614864   \n",
       "\n",
       "                                                                          \n",
       "                                 recomp-astar_over_recomp-inc3  max_diff  \n",
       "model log decomposition SP label                                          \n",
       "P430  L19 sese_manual   case_785                      0.789688  1.047901  \n",
       "                        case_69                       0.741530  1.116568  \n",
       "                        case_33                       0.744000  0.818665  \n",
       "                        case_797                      0.757860  1.302021  \n",
       "                        case_784                      0.790864  0.790864  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.loc[:, idx['Total Time including setup (us)', :]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = '../../prediction-data/final-data.csv'\n",
    "\n",
    "# export dataframe after computing k times differences!\n",
    "full_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the no-duplicates dataframe\n",
    "Two rows are considered duplicates if they have the values in:\n",
    "- all of the model_trace_features columns\n",
    "- same cost of the alignment\n",
    "\n",
    "Note that they do not need the same alignment, i.e., same number of legal move types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before filtering duplicates: 245478\n",
      "Number of rows after filtering duplicates: 185848\n",
      "Number of rows removed: 59630\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows before filtering duplicates: {}'.format(full_df.shape[0]))\n",
    "\n",
    "select_level_0 = ('model_trace_features', 'Cost of the alignment')\n",
    "select_level_1 = slice(None)\n",
    "\n",
    "duplicate_rows = full_df.loc[:, idx[select_level_0, select_level_1]].duplicated()\n",
    "uniq_full_df = full_df[~duplicate_rows]\n",
    "\n",
    "print('Number of rows after filtering duplicates: {}'.format(uniq_full_df.shape[0]))\n",
    "print('Number of rows removed: {}'.format(full_df.shape[0] - uniq_full_df.shape[0]))\n",
    "\n",
    "out_fp = '../../prediction-data/uniq-final-data.csv'\n",
    "uniq_full_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_description = full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ('Min', 'Total Time including setup (us)')\n",
    "min_total_astar = full_df.loc[:, col] == 'astar'\n",
    "min_total_inc3 = full_df.loc[:, col] == 'inc3'\n",
    "min_total_r_astar = full_df.loc[:, col] == 'recomp-astar'\n",
    "min_total_r_inc3 = full_df.loc[:, col] == 'recomp-inc3'\n",
    "\n",
    "total_win_astar_secs = full_df.loc[min_total_astar, idx[('Total Time including setup (us)'), :]] / 1000000\n",
    "total_win_inc3_secs = full_df.loc[min_total_inc3, idx[('Total Time including setup (us)'), :]] / 1000000\n",
    "total_win_r_astar_secs = full_df.loc[min_total_r_astar, idx[('Total Time including setup (us)'), :]] / 1000000\n",
    "total_win_r_inc3_secs = full_df.loc[min_total_r_inc3, idx[('Total Time including setup (us)'), :]] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_win_r_inc3_secs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "class_dist = full_df.loc[:, idx[('Min'), ('Total Time including setup (us)')]].value_counts()\n",
    "class_dist.plot(kind='bar', ax=ax, color='dodgerblue', alpha=0.5, edgecolor='black', linewidth=1.5);\n",
    "\n",
    "xticklabels = [\n",
    "    'CLASSIC', 'CLASSIC-SP', 'RECOMPOSE', 'RECOMPOSE-SP'\n",
    "]\n",
    "ax.set_xticklabels(xticklabels, size=20, rotation=0)\n",
    "\n",
    "total_wins = [\n",
    "    total_win_astar_secs,\n",
    "    total_win_inc3_secs,\n",
    "    total_win_r_astar_secs,\n",
    "    total_win_r_inc3_secs\n",
    "]\n",
    "\n",
    "algo = [\n",
    "    'astar', 'inc3', 'recomp-astar', 'recomp-inc3'\n",
    "]\n",
    "\n",
    "means = [total_wins[i].loc[:, ('Total Time including setup (us)', algo[i])].mean() for i in range(4)]\n",
    "std = [ss.std() for ss in total_wins]\n",
    "\n",
    "# ax_twin = ax.twinx()\n",
    "\n",
    "# ax_twin.plot(means, marker='^', linestyle='', )\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./class-dist.svg', bbox_inches='tight', rasterized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[(concat_df[('Min', 'Total Time including setup (us)')] == 'astar'),('Cost of the alignment','astar')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[(concat_df[('Min', 'Total Time including setup (us)')] == 'inc3'),('Cost of the alignment', 'inc3')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = concat_df['n_sync_move'] + concat_df['n_invis_move'] + concat_df['n_model_move'] + concat_df['n_log_move']\n",
    "temp_df.columns = pd.MultiIndex.from_product([['alignment_length'], ['astar', 'inc3', 'recomp-astar', 'recomp-inc3']])\n",
    "concat_df = pd.concat([concat_df, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "astar_invalid = concat_df.loc[:,('is_valid','astar')] == False\n",
    "min_is_astar = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'astar'\n",
    "concat_df.loc[(astar_invalid)&(min_is_astar),idx[('is_valid', slice(None))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "concat_df.loc[:, idx[('Min', 'is_valid'),('Total Time including setup (us)', 'astar', 'inc3', 'recomp-astar', 'recomp-inc3')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astar_invalid = concat_df.loc[:,('is_valid', 'astar')] == False\n",
    "inc3_invalid = concat_df.loc[:,('is_valid', 'inc3')] == False\n",
    "recomp_astar_invalid = concat_df.loc[:,('is_valid', 'recomp-astar')] == False\n",
    "recomp_inc3_invalid = concat_df.loc[:,('is_valid', 'recomp-inc3')] == False\n",
    "min_total_astar = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'astar'\n",
    "min_total_inc3 = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'inc3'\n",
    "min_total_recomp_astar = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-astar'\n",
    "min_total_recomp_inc3 = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-inc3'\n",
    "min_align_astar = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'astar'\n",
    "min_align_inc3 = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'inc3'\n",
    "min_align_recomp_astar = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'recomp-astar'\n",
    "min_align_recomp_inc3 = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'recomp-inc3'\n",
    "\n",
    "concat_df.loc[astar_invalid & inc3_invalid & recomp_astar_invalid & recomp_inc3_invalid,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[astar_invalid | inc3_invalid | recomp_astar_invalid | recomp_inc3_invalid,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[astar_invalid & min_astar, idx[('Min', 'is_valid'),('Total Time including setup (us)', 'astar')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[astar_invalid & min_align_astar,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[inc3_invalid & min_total_inc3,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[recomp_astar_invalid & min_total_recomp_astar, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[recomp_inc3_invalid & min_total_recomp_inc3, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['Total Time including setup (us)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[(concat_df[('Min', 'Total Time including setup (us)')] == 'recomp-inc3'),[('Cost of the alignment','astar'), ('')]].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (alignclf)",
   "language": "python",
   "name": "alignclf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
