{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/jonathan/.ipython/profile_default/startup/01-setup.py\n",
    "# start up settings for jupyter notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# use plt.style.available() to check out available styles\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 15.0\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set the max column width\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "# to avoid have warnings from chained assignments\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fp = '../../prediction-data/clst-2018-12-generic_50-inc0-net1-predictive-output.csv'\n",
    "df = pd.read_csv(fp, header=[0, 1])\n",
    "df.rename(columns={\n",
    "    'Unnamed: 0_level_1': '',\n",
    "    'Unnamed: 1_level_1': '',\n",
    "    'Unnamed: 2_level_1': ''\n",
    "}, level=1, inplace=True)\n",
    "\n",
    "columns = list(df.columns)\n",
    "decomposition_type = 'generic_50'\n",
    "df['decomposition'] = decomposition_type\n",
    "columns = [('model', ''), ('log', ''), ('decomposition', ''), ('SP label', '')] + columns[3:]\n",
    "df = df[columns]\n",
    "\n",
    "df.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../prediction-data/'\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    if 'inc0' in f or 'final-data' in f:\n",
    "        continue\n",
    "    fp = os.path.join(data_dir, f)\n",
    "    \n",
    "    if not os.path.isfile(fp):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(fp, header=[0, 1])\n",
    "    df.rename(columns={\n",
    "        'Unnamed: 0_level_1': '',\n",
    "        'Unnamed: 1_level_1': '',\n",
    "        'Unnamed: 2_level_1': '',\n",
    "        'Unnamed: 3_level_1': ''\n",
    "    }, level=1, inplace=True)\n",
    "    df_list.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering all invalid no. of rows: 406130\n",
      "After filtering all invalid no. of rows: 405795\n",
      "335 traces invalid for all algorithms\n",
      "Before filtering negative cost rows: 405795\n",
      "After filtering negative cost rows: 405357\n",
      "438 traces invalid\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.concat(df_list, axis=0, sort=False)\n",
    "base_df.set_index(['model', 'log', 'decomposition', 'SP label'], inplace=True)\n",
    "\n",
    "# remove traces for which all algorithms are invalid\n",
    "astar_invalid = (base_df.loc[:,('is_valid', 'astar')] == False) | (base_df.loc[:, ('is_valid', 'astar')].isnull())\n",
    "inc3_invalid = (base_df.loc[:,('is_valid', 'inc3')] == False) | (base_df.loc[:,('is_valid', 'inc3')].isnull())\n",
    "recomp_astar_invalid = (base_df.loc[:,('is_valid', 'recomp-astar')] == False) | (base_df.loc[:,('is_valid', 'recomp-astar')].isnull())\n",
    "recomp_inc3_invalid = (base_df.loc[:,('is_valid', 'recomp-inc3')] == False) | (base_df.loc[:,('is_valid', 'recomp-inc3')].isnull())\n",
    "all_invalid = astar_invalid & inc3_invalid & recomp_astar_invalid & recomp_inc3_invalid\n",
    "\n",
    "before_n_rows = base_df.shape[0]\n",
    "print('Before filtering all invalid no. of rows: {}'.format(before_n_rows))\n",
    "\n",
    "base_df = base_df.loc[~all_invalid, :]\n",
    "\n",
    "after_n_rows = base_df.shape[0]\n",
    "print('After filtering all invalid no. of rows: {}'.format(after_n_rows))\n",
    "print('{} traces invalid for all algorithms'.format(before_n_rows - after_n_rows))\n",
    "\n",
    "cost_is_neg_recomp_astar = base_df.loc[:, ('Cost of the alignment', 'recomp-astar')] == -1\n",
    "cost_is_neg_recomp_inc3 = base_df.loc[:, ('Cost of the alignment', 'recomp-inc3')] == -1\n",
    "\n",
    "before_n_rows = base_df.shape[0]\n",
    "print('Before filtering negative cost rows: {}'.format(before_n_rows))\n",
    "\n",
    "base_df = base_df.loc[~(cost_is_neg_recomp_astar | cost_is_neg_recomp_inc3), :]\n",
    "\n",
    "after_n_rows = base_df.shape[0]\n",
    "print('After filtering negative cost rows: {}'.format(after_n_rows))\n",
    "print('{} traces invalid'.format(before_n_rows - after_n_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cost of the alignment', 'Heuristics computed', 'Heuristics derived',\n",
       "       'Heuristics estimated', 'Markings added to closed set',\n",
       "       'Markings polled from queue', 'Markings queued', 'Markings reached',\n",
       "       'Min', 'Time to compute alignment (us)',\n",
       "       'Total Time including setup (us)', 'is_valid', 'n_invis_move',\n",
       "       'n_log_move', 'n_model_move', 'n_sync_move', 'result_dir'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.columns.get_level_values(level=0).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and correct errors with algorithms yielding invalid alignments but has the minimum time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Time including setup (us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false min astar: 0\n",
      "No. of false min inc3: 0\n",
      "No. of false min recomp astar: 0\n",
      "No. of false min recomp inc3: 0\n"
     ]
    }
   ],
   "source": [
    "min_total_astar = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'astar'\n",
    "min_total_inc3 = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'inc3'\n",
    "min_total_r_astar = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-astar'\n",
    "min_total_r_inc3 = base_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-inc3'\n",
    "\n",
    "false_min_astar = base_df.loc[astar_invalid & min_total_astar, ]\n",
    "false_min_inc3 = base_df.loc[inc3_invalid & min_total_inc3, ]\n",
    "false_min_r_astar = base_df.loc[recomp_astar_invalid & min_total_r_astar, ]\n",
    "false_min_r_inc3 = base_df.loc[recomp_inc3_invalid & min_total_r_inc3, ]\n",
    "\n",
    "print('No. of false min astar: {}'.format(false_min_astar.shape[0]))\n",
    "print('No. of false min inc3: {}'.format(false_min_inc3.shape[0]))\n",
    "print('No. of false min recomp astar: {}'.format(false_min_r_astar.shape[0]))\n",
    "print('No. of false min recomp inc3: {}'.format(false_min_r_inc3.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to compute alignment (us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of false min align time astar: 0\n",
      "No. of false min align time inc3: 0\n",
      "No. of false min align time recomp astar: 0\n",
      "No. of false min align time recomp inc3: 0\n"
     ]
    }
   ],
   "source": [
    "col = ('Min', 'Time to compute alignment (us)')\n",
    "min_align_astar = base_df.loc[:,col] == 'astar'\n",
    "min_align_inc3 = base_df.loc[:,col] == 'inc3'\n",
    "min_align_r_astar = base_df.loc[:,col] == 'recomp-astar'\n",
    "min_align_r_inc3 = base_df.loc[:,col] == 'recomp-inc3'\n",
    "\n",
    "false_min_astar = base_df.loc[astar_invalid & min_align_astar, ]\n",
    "false_min_inc3 = base_df.loc[inc3_invalid & min_align_inc3, ]\n",
    "false_min_r_astar = base_df.loc[recomp_astar_invalid & min_align_r_astar, ]\n",
    "false_min_r_inc3 = base_df.loc[recomp_inc3_invalid & min_align_r_inc3, ]\n",
    "\n",
    "print('No. of false min align time astar: {}'.format(false_min_astar.shape[0]))\n",
    "print('No. of false min align time inc3: {}'.format(false_min_inc3.shape[0]))\n",
    "print('No. of false min align time recomp astar: {}'.format(false_min_r_astar.shape[0]))\n",
    "print('No. of false min align time recomp inc3: {}'.format(false_min_r_inc3.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Cost of the alignment</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Heuristics computed</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Heuristics derived</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">n_log_move</th>\n",
       "      <th colspan=\"4\" halign=\"left\">n_model_move</th>\n",
       "      <th colspan=\"4\" halign=\"left\">n_sync_move</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>...</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "      <th>astar</th>\n",
       "      <th>inc3</th>\n",
       "      <th>recomp-astar</th>\n",
       "      <th>recomp-inc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>405357.000000</td>\n",
       "      <td>360414.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>225605.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>360414.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>225605.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>360414.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>225605.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>360414.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>225605.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>360414.000000</td>\n",
       "      <td>405357.000000</td>\n",
       "      <td>225605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.354786</td>\n",
       "      <td>56.540306</td>\n",
       "      <td>57.446039</td>\n",
       "      <td>53.332923</td>\n",
       "      <td>694.780088</td>\n",
       "      <td>6.639609</td>\n",
       "      <td>765.382446</td>\n",
       "      <td>79.806853</td>\n",
       "      <td>304.113174</td>\n",
       "      <td>264.569032</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248865</td>\n",
       "      <td>3.938986</td>\n",
       "      <td>3.724714</td>\n",
       "      <td>3.658046</td>\n",
       "      <td>3.739348</td>\n",
       "      <td>3.485765</td>\n",
       "      <td>67.201094</td>\n",
       "      <td>67.147600</td>\n",
       "      <td>67.267073</td>\n",
       "      <td>66.868208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>137.512584</td>\n",
       "      <td>135.766728</td>\n",
       "      <td>138.066793</td>\n",
       "      <td>130.484134</td>\n",
       "      <td>2037.921552</td>\n",
       "      <td>32.927709</td>\n",
       "      <td>2090.003476</td>\n",
       "      <td>44.027746</td>\n",
       "      <td>645.611416</td>\n",
       "      <td>696.914106</td>\n",
       "      <td>...</td>\n",
       "      <td>10.451754</td>\n",
       "      <td>9.903699</td>\n",
       "      <td>8.551612</td>\n",
       "      <td>8.359467</td>\n",
       "      <td>8.596439</td>\n",
       "      <td>8.066557</td>\n",
       "      <td>35.104791</td>\n",
       "      <td>35.594206</td>\n",
       "      <td>35.226600</td>\n",
       "      <td>36.636203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>3090.000000</td>\n",
       "      <td>1224.000000</td>\n",
       "      <td>38800.000000</td>\n",
       "      <td>1191.000000</td>\n",
       "      <td>25251.000000</td>\n",
       "      <td>989.000000</td>\n",
       "      <td>23185.000000</td>\n",
       "      <td>16646.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cost of the alignment                                               \\\n",
       "                      astar           inc3   recomp-astar    recomp-inc3   \n",
       "count         405357.000000  360414.000000  405357.000000  225605.000000   \n",
       "mean              57.354786      56.540306      57.446039      53.332923   \n",
       "std              137.512584     135.766728     138.066793     130.484134   \n",
       "min                0.000000       0.000000       0.000000       0.000000   \n",
       "25%                0.000000       0.000000       0.000000       0.000000   \n",
       "50%                0.000000       0.000000       0.000000       0.000000   \n",
       "75%               22.000000      24.000000      22.000000      14.000000   \n",
       "max             1256.000000    1256.000000    3090.000000    1224.000000   \n",
       "\n",
       "      Heuristics computed                                               \\\n",
       "                    astar           inc3   recomp-astar    recomp-inc3   \n",
       "count       405357.000000  360414.000000  405357.000000  225605.000000   \n",
       "mean           694.780088       6.639609     765.382446      79.806853   \n",
       "std           2037.921552      32.927709    2090.003476      44.027746   \n",
       "min              1.000000       1.000000      12.000000      12.000000   \n",
       "25%              1.000000       1.000000      71.000000      69.000000   \n",
       "50%              1.000000       1.000000      74.000000      75.000000   \n",
       "75%              8.000000       2.000000      87.000000      78.000000   \n",
       "max          38800.000000    1191.000000   25251.000000     989.000000   \n",
       "\n",
       "      Heuristics derived                     ...           n_log_move  \\\n",
       "                   astar           inc3      ...         recomp-astar   \n",
       "count      405357.000000  360414.000000      ...        405357.000000   \n",
       "mean          304.113174     264.569032      ...             4.248865   \n",
       "std           645.611416     696.914106      ...            10.451754   \n",
       "min             3.000000       3.000000      ...             0.000000   \n",
       "25%            58.000000      58.000000      ...             0.000000   \n",
       "50%            82.000000      82.000000      ...             0.000000   \n",
       "75%           174.000000     166.000000      ...             1.000000   \n",
       "max         23185.000000   16646.000000      ...           309.000000   \n",
       "\n",
       "                       n_model_move                                \\\n",
       "         recomp-inc3          astar           inc3   recomp-astar   \n",
       "count  225605.000000  405357.000000  360414.000000  405357.000000   \n",
       "mean        3.938986       3.724714       3.658046       3.739348   \n",
       "std         9.903699       8.551612       8.359467       8.596439   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         1.000000       2.000000       2.000000       2.000000   \n",
       "max        98.000000      81.000000      78.000000      81.000000   \n",
       "\n",
       "                        n_sync_move                                \\\n",
       "         recomp-inc3          astar           inc3   recomp-astar   \n",
       "count  225605.000000  405357.000000  360414.000000  405357.000000   \n",
       "mean        3.485765      67.201094      67.147600      67.267073   \n",
       "std         8.066557      35.104791      35.594206      35.226600   \n",
       "min         0.000000      -1.000000      -1.000000       0.000000   \n",
       "25%         0.000000      45.000000      45.000000      45.000000   \n",
       "50%         0.000000      58.000000      57.000000      58.000000   \n",
       "75%         2.000000      79.000000      79.000000      79.000000   \n",
       "max        78.000000     419.000000     419.000000     419.000000   \n",
       "\n",
       "                      \n",
       "         recomp-inc3  \n",
       "count  225605.000000  \n",
       "mean       66.868208  \n",
       "std        36.636203  \n",
       "min         0.000000  \n",
       "25%        45.000000  \n",
       "50%        57.000000  \n",
       "75%        79.000000  \n",
       "max       419.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and trace features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '../../prediction-data/features/net1-feature.csv'\n",
    "df = pd.read_csv(fp)\n",
    "\n",
    "fp = '../../prediction-data/features/P241-feature.csv'\n",
    "df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>trace_length</th>\n",
       "      <th>n_activity</th>\n",
       "      <th>activity_repeat_mean</th>\n",
       "      <th>activity_repeat_std</th>\n",
       "      <th>snp_n_transition</th>\n",
       "      <th>snp_n_inv_transition</th>\n",
       "      <th>snp_n_dup_transition</th>\n",
       "      <th>snp_n_uniq_transition</th>\n",
       "      <th>snp_inv_transition_in_degree_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>subnet_n_dup_transition_mean</th>\n",
       "      <th>subnet_n_dup_transition_std</th>\n",
       "      <th>subnet_n_uniq_transition_mean</th>\n",
       "      <th>subnet_n_uniq_transition_std</th>\n",
       "      <th>subnet_n_place_mean</th>\n",
       "      <th>subnet_n_place_std</th>\n",
       "      <th>subnet_n_arc_mean</th>\n",
       "      <th>subnet_n_arc_std</th>\n",
       "      <th>decomposition</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case_0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.139785</td>\n",
       "      <td>0.543567</td>\n",
       "      <td>355.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case_1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.032967</td>\n",
       "      <td>0.179540</td>\n",
       "      <td>331.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case_10</td>\n",
       "      <td>112.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.244444</td>\n",
       "      <td>0.768935</td>\n",
       "      <td>367.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case_100</td>\n",
       "      <td>105.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.613244</td>\n",
       "      <td>353.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case_101</td>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1.011494</td>\n",
       "      <td>0.107211</td>\n",
       "      <td>319.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.581246</td>\n",
       "      <td>52.0</td>\n",
       "      <td>67.557383</td>\n",
       "      <td>116.666667</td>\n",
       "      <td>141.454351</td>\n",
       "      <td>sese_manual</td>\n",
       "      <td>L50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     caseid  trace_length  n_activity  activity_repeat_mean  \\\n",
       "0    case_0         106.0        93.0              1.139785   \n",
       "1    case_1          94.0        91.0              1.032967   \n",
       "2   case_10         112.0        90.0              1.244444   \n",
       "3  case_100         105.0        91.0              1.153846   \n",
       "4  case_101          88.0        87.0              1.011494   \n",
       "\n",
       "   activity_repeat_std  snp_n_transition  snp_n_inv_transition  \\\n",
       "0             0.543567             355.0                  26.0   \n",
       "1             0.179540             331.0                  26.0   \n",
       "2             0.768935             367.0                  26.0   \n",
       "3             0.613244             353.0                  26.0   \n",
       "4             0.107211             319.0                  26.0   \n",
       "\n",
       "   snp_n_dup_transition  snp_n_uniq_transition  \\\n",
       "0                  40.0                  289.0   \n",
       "1                  12.0                  293.0   \n",
       "2                  62.0                  279.0   \n",
       "3                  42.0                  285.0   \n",
       "4                   4.0                  289.0   \n",
       "\n",
       "   snp_inv_transition_in_degree_mean ...   subnet_n_dup_transition_mean  \\\n",
       "0                                2.0 ...                            0.0   \n",
       "1                                2.0 ...                            0.0   \n",
       "2                                2.0 ...                            0.0   \n",
       "3                                2.0 ...                            0.0   \n",
       "4                                2.0 ...                            0.0   \n",
       "\n",
       "   subnet_n_dup_transition_std  subnet_n_uniq_transition_mean  \\\n",
       "0                          0.0                           40.0   \n",
       "1                          0.0                           40.0   \n",
       "2                          0.0                           40.0   \n",
       "3                          0.0                           40.0   \n",
       "4                          0.0                           40.0   \n",
       "\n",
       "   subnet_n_uniq_transition_std  subnet_n_place_mean  subnet_n_place_std  \\\n",
       "0                     41.581246                 52.0           67.557383   \n",
       "1                     41.581246                 52.0           67.557383   \n",
       "2                     41.581246                 52.0           67.557383   \n",
       "3                     41.581246                 52.0           67.557383   \n",
       "4                     41.581246                 52.0           67.557383   \n",
       "\n",
       "   subnet_n_arc_mean  subnet_n_arc_std  decomposition  log  \n",
       "0         116.666667        141.454351    sese_manual  L50  \n",
       "1         116.666667        141.454351    sese_manual  L50  \n",
       "2         116.666667        141.454351    sese_manual  L50  \n",
       "3         116.666667        141.454351    sese_manual  L50  \n",
       "4         116.666667        141.454351    sese_manual  L50  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = '../../prediction-data/features/'\n",
    "\n",
    "feature_df_list = []\n",
    "\n",
    "for f in os.listdir(feature_dir):\n",
    "    fp = os.path.join(feature_dir, f)\n",
    "    model = f.replace('-feature.csv', '')\n",
    "    df = pd.read_csv(fp)\n",
    "    df['model'] = model\n",
    "    feature_df_list.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.concat(feature_df_list, axis=0, sort=False)\n",
    "feature_df.rename(columns={'caseid': 'SP label'}, inplace=True) # for later convenience on merging with base_df\n",
    "feature_df.set_index(['model', 'log', 'decomposition', 'SP label'], inplace=True)\n",
    "feature_df.columns = pd.MultiIndex.from_product([['model_trace_features'], feature_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = base_df.merge(feature_df, on=['model', 'log', 'decomposition', 'SP label'], how='inner')\n",
    "out_fp = '../../prediction-data/final-data.csv'\n",
    "\n",
    "full_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the no-duplicates dataframe\n",
    "Two rows are considered duplicates if they have the values in:\n",
    "- all of the model_trace_features columns\n",
    "- same cost of the alignment\n",
    "\n",
    "Note that they do not need the same alignment, i.e., same number of legal move types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before filtering duplicates: 251637\n",
      "Number of rows after filtering duplicates: 191221\n",
      "Number of rows removed: 60416\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows before filtering duplicates: {}'.format(full_df.shape[0]))\n",
    "\n",
    "select_level_0 = ('model_trace_features', 'Cost of the alignment')\n",
    "select_level_1 = slice(None)\n",
    "\n",
    "duplicate_rows = full_df.loc[:, idx[select_level_0, select_level_1]].duplicated()\n",
    "uniq_full_df = full_df[~duplicate_rows]\n",
    "\n",
    "print('Number of rows after filtering duplicates: {}'.format(uniq_full_df.shape[0]))\n",
    "print('Number of rows removed: {}'.format(full_df.shape[0] - uniq_full_df.shape[0]))\n",
    "\n",
    "out_fp = '../../prediction-data/uniq-final-data.csv'\n",
    "uniq_full_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df_description = full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ('Min', 'Total Time including setup (us)')\n",
    "min_total_astar = full_df.loc[:, col] == 'astar'\n",
    "min_total_inc3 = full_df.loc[:, col] == 'inc3'\n",
    "min_total_r_astar = full_df.loc[:, col] == 'recomp-astar'\n",
    "min_total_r_inc3 = full_df.loc[:, col] == 'recomp-inc3'\n",
    "\n",
    "total_win_astar_secs = full_df.loc[min_total_astar, idx[('Total Time including setup (us)'), :]] / 1000000\n",
    "total_win_inc3_secs = full_df.loc[min_total_inc3, idx[('Total Time including setup (us)'), :]] / 1000000\n",
    "total_win_r_astar_secs = full_df.loc[min_total_r_astar, idx[('Total Time including setup (us)'), :]] / 1000000\n",
    "total_win_r_inc3_secs = full_df.loc[min_total_r_inc3, idx[('Total Time including setup (us)'), :]] / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_win_r_inc3_secs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "class_dist = full_df.loc[:, idx[('Min'), ('Total Time including setup (us)')]].value_counts()\n",
    "class_dist.plot(kind='bar', ax=ax, color='dodgerblue', alpha=0.5, edgecolor='black', linewidth=1.5);\n",
    "\n",
    "xticklabels = [\n",
    "    'CLASSIC', 'CLASSIC-SP', 'RECOMPOSE', 'RECOMPOSE-SP'\n",
    "]\n",
    "ax.set_xticklabels(xticklabels, size=20, rotation=0)\n",
    "\n",
    "total_wins = [\n",
    "    total_win_astar_secs,\n",
    "    total_win_inc3_secs,\n",
    "    total_win_r_astar_secs,\n",
    "    total_win_r_inc3_secs\n",
    "]\n",
    "\n",
    "algo = [\n",
    "    'astar', 'inc3', 'recomp-astar', 'recomp-inc3'\n",
    "]\n",
    "\n",
    "means = [total_wins[i].loc[:, ('Total Time including setup (us)', algo[i])].mean() for i in range(4)]\n",
    "std = [ss.std() for ss in total_wins]\n",
    "\n",
    "# ax_twin = ax.twinx()\n",
    "\n",
    "# ax_twin.plot(means, marker='^', linestyle='', )\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('./class-dist.svg', bbox_inches='tight', rasterized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[(concat_df[('Min', 'Total Time including setup (us)')] == 'astar'),('Cost of the alignment','astar')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[(concat_df[('Min', 'Total Time including setup (us)')] == 'inc3'),('Cost of the alignment', 'inc3')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = concat_df['n_sync_move'] + concat_df['n_invis_move'] + concat_df['n_model_move'] + concat_df['n_log_move']\n",
    "temp_df.columns = pd.MultiIndex.from_product([['alignment_length'], ['astar', 'inc3', 'recomp-astar', 'recomp-inc3']])\n",
    "concat_df = pd.concat([concat_df, temp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "astar_invalid = concat_df.loc[:,('is_valid','astar')] == False\n",
    "min_is_astar = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'astar'\n",
    "concat_df.loc[(astar_invalid)&(min_is_astar),idx[('is_valid', slice(None))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "concat_df.loc[:, idx[('Min', 'is_valid'),('Total Time including setup (us)', 'astar', 'inc3', 'recomp-astar', 'recomp-inc3')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astar_invalid = concat_df.loc[:,('is_valid', 'astar')] == False\n",
    "inc3_invalid = concat_df.loc[:,('is_valid', 'inc3')] == False\n",
    "recomp_astar_invalid = concat_df.loc[:,('is_valid', 'recomp-astar')] == False\n",
    "recomp_inc3_invalid = concat_df.loc[:,('is_valid', 'recomp-inc3')] == False\n",
    "min_total_astar = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'astar'\n",
    "min_total_inc3 = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'inc3'\n",
    "min_total_recomp_astar = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-astar'\n",
    "min_total_recomp_inc3 = concat_df.loc[:,('Min', 'Total Time including setup (us)')] == 'recomp-inc3'\n",
    "min_align_astar = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'astar'\n",
    "min_align_inc3 = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'inc3'\n",
    "min_align_recomp_astar = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'recomp-astar'\n",
    "min_align_recomp_inc3 = concat_df.loc[:,('Min', 'Time to compute alignment (us)')] == 'recomp-inc3'\n",
    "\n",
    "concat_df.loc[astar_invalid & inc3_invalid & recomp_astar_invalid & recomp_inc3_invalid,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[astar_invalid | inc3_invalid | recomp_astar_invalid | recomp_inc3_invalid,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[astar_invalid & min_astar, idx[('Min', 'is_valid'),('Total Time including setup (us)', 'astar')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[astar_invalid & min_align_astar,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[inc3_invalid & min_total_inc3,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[recomp_astar_invalid & min_total_recomp_astar, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[recomp_inc3_invalid & min_total_recomp_inc3, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['Total Time including setup (us)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.loc[(concat_df[('Min', 'Total Time including setup (us)')] == 'recomp-inc3'),[('Cost of the alignment','astar'), ('')]].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (alignclf)",
   "language": "python",
   "name": "alignclf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
