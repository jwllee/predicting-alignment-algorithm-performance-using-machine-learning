{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/jonathan/.ipython/profile_default/startup/01-setup.py\n",
    "# start up settings for jupyter notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "# use plt.style.available() to check out available styles\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.size'] = 15.0\n",
    "plt.rcParams['axes.labelsize'] = 15.0\n",
    "plt.rcParams['xtick.labelsize'] = 15.0\n",
    "plt.rcParams['ytick.labelsize'] = 15.0\n",
    "plt.rcParams['legend.fontsize'] = 15.0\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set the max column width\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "# to avoid have warnings from chained assignments\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/2018/code/alignment-algorithm-classifier/alignclf-venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base df shape: (245478, 258)\n",
      "Uniq base df shape: (185848, 258)\n",
      "K-2 df shape: (86469, 258)\n",
      "K-2 unique df shape: (74582, 258)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../prediction-data/'\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    if 'inc0' in f or 'final-data' in f:\n",
    "        continue\n",
    "    fp = os.path.join(data_dir, f)\n",
    "    \n",
    "    if not os.path.isfile(fp):\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(fp, header=[0, 1])\n",
    "    df.rename(columns={\n",
    "        'Unnamed: 0_level_1': '',\n",
    "        'Unnamed: 1_level_1': '',\n",
    "        'Unnamed: 2_level_1': '',\n",
    "        'Unnamed: 3_level_1': ''\n",
    "    }, level=1, inplace=True)\n",
    "    df_list.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.concat(df_list, axis=0, sort=False)\n",
    "base_df.set_index(['model', 'log', 'decomposition', 'SP label'], inplace=True)\n",
    "\n",
    "# remove traces for which all algorithms are invalid\n",
    "astar_invalid = (base_df.loc[:,('is_valid', 'astar')] == False) | (base_df.loc[:, ('is_valid', 'astar')].isnull())\n",
    "inc3_invalid = (base_df.loc[:,('is_valid', 'inc3')] == False) | (base_df.loc[:,('is_valid', 'inc3')].isnull())\n",
    "recomp_astar_invalid = (base_df.loc[:,('is_valid', 'recomp-astar')] == False) | (base_df.loc[:,('is_valid', 'recomp-astar')].isnull())\n",
    "recomp_inc3_invalid = (base_df.loc[:,('is_valid', 'recomp-inc3')] == False) | (base_df.loc[:,('is_valid', 'recomp-inc3')].isnull())\n",
    "all_invalid = astar_invalid & inc3_invalid & recomp_astar_invalid & recomp_inc3_invalid\n",
    "\n",
    "before_n_rows = base_df.shape[0]\n",
    "print('Before filtering all invalid no. of rows: {}'.format(before_n_rows))\n",
    "\n",
    "base_df = base_df.loc[~all_invalid, :]\n",
    "\n",
    "after_n_rows = base_df.shape[0]\n",
    "print('After filtering all invalid no. of rows: {}'.format(after_n_rows))\n",
    "print('{} traces invalid for all algorithms'.format(before_n_rows - after_n_rows))\n",
    "\n",
    "cost_is_neg_recomp_astar = base_df.loc[:, ('Cost of the alignment', 'recomp-astar')] == -1\n",
    "cost_is_neg_recomp_inc3 = base_df.loc[:, ('Cost of the alignment', 'recomp-inc3')] == -1\n",
    "\n",
    "before_n_rows = base_df.shape[0]\n",
    "print('Before filtering negative cost rows: {}'.format(before_n_rows))\n",
    "\n",
    "base_df = base_df.loc[~(cost_is_neg_recomp_astar | cost_is_neg_recomp_inc3), :]\n",
    "\n",
    "after_n_rows = base_df.shape[0]\n",
    "print('After filtering negative cost rows: {}'.format(after_n_rows))\n",
    "print('{} traces invalid'.format(before_n_rows - after_n_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = '../prediction-data/features/'\n",
    "\n",
    "feature_df_list = dict()\n",
    "\n",
    "for f in os.listdir(feature_dir):\n",
    "    fp = os.path.join(feature_dir, f)\n",
    "    \n",
    "    if not os.path.isfile(fp):\n",
    "        continue\n",
    "    \n",
    "    model = f.replace('-feature.csv', '')\n",
    "    df = pd.read_csv(fp)\n",
    "    df['model'] = model\n",
    "    feature_df_list = df\n",
    "\n",
    "feature_df = pd.concat(feature_df_list, axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge feature data and performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = base_df.merge(feature_df, on=('model', 'log', 'decomposition', 'SP label'), how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the no-duplicates dataframe\n",
    "Two rows are considered duplicates if they have the values in:\n",
    "- all of the model_trace_features columns\n",
    "- same cost of the alignment\n",
    "\n",
    "Note that they do not need the same alignment, i.e., same number of legal move types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows before filtering duplicates: {}'.format(full_df.shape[0]))\n",
    "\n",
    "select_level_0 = ('model_trace_features', 'Cost of the alignment')\n",
    "select_level_1 = slice(None)\n",
    "\n",
    "duplicate_rows = full_df.loc[:, idx[select_level_0, select_level_1]].duplicated()\n",
    "uniq_full_df = full_df[~duplicate_rows]\n",
    "\n",
    "print('Number of rows after filtering duplicates: {}'.format(uniq_full_df.shape[0]))\n",
    "print('Number of rows removed: {}'.format(full_df.shape[0] - uniq_full_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = '../prediction-data/final-data.csv'\n",
    "\n",
    "# export dataframe after computing k times differences!\n",
    "full_df.reset_index(drop=False).to_csv(out_fp, index=False)\n",
    "\n",
    "out_fp = '../../prediction-data/uniq-final-data.csv'\n",
    "uniq_full_df.reset_index(drop=False).to_csv(out_fp, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (alignclf)",
   "language": "python",
   "name": "alignclf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
